C++ https://github.com/ggerganov/llama.cpp modularized server setup for bindings with continuous batching support for multi-user inference. This is designed to be exposed as C-compatible binding interface, this repo serves as an example of pure C++ and is mostly here to serve as an example.

Specialized Features:
Inference rewinding
Multi-User inference with Continuous Batching
Minimum tokens
Fully asynchronous inference design for FFI servers

This is a modernized version of the (more compatible for general users) bindings I wrote for https://github.com/theroyallab/YALS
